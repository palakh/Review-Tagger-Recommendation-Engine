{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inventory_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK0hTgK6jBJj"
      },
      "source": [
        "**Code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KLtQFwUOrD8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebhlHlt8O0k4"
      },
      "source": [
        "df = pd.read_csv('/content/data.csv')\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMOP6R5VYBr6"
      },
      "source": [
        "**Data Cleaning Step 1**\n",
        "\n",
        "**Looking for incorrect Scans**\n",
        "\n",
        "1. Identify the barcodes with their timestamps where they have these issues\n",
        "\n",
        "2. Remove System Design issues\n",
        "\n",
        "3. Drop the rows where we have above mentioned issues from our main dataframe\n",
        "\n",
        "4. For issues with 3 rows for same timestamp in one barcode - No pattern identified\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8B4_AbBIoe9"
      },
      "source": [
        "temp = df.groupby(['barcode','timestamp'])['scan_to_station'].count().reset_index().sort_values(by='scan_to_station',ascending=False)\n",
        "temp\n",
        "\n",
        "temp_2 = temp[temp['scan_to_station']==2].reset_index().drop('index',axis=1)\n",
        "temp_2.shape\n",
        "\n",
        "temp_2_df = pd.DataFrame()\n",
        "for i in temp_2.index:\n",
        "  match = df[(df['barcode']== temp_2['barcode'].iloc[i]) & (df['timestamp']==temp_2['timestamp'].iloc[i])]\n",
        "  temp_2_df = pd.concat([temp_2_df,match])\n",
        "\n",
        "temp_2_df\n",
        "temp_2_df = temp_2_df[ ~((temp_2_df['scan_from_station'] == 'Customer Receiving') & (temp_2_df['scan_to_station'] == 'Pre-Inspection')) ]\n",
        "temp_2_df = temp_2_df[ ~((temp_2_df['scan_from_station'] == 'Customer') & (temp_2_df['scan_to_station'] == 'Customer Receiving')) ]\n",
        "temp_2_df = temp_2_df.sort_values(by=['barcode','timestamp']).reset_index().drop('index',axis = 1)\n",
        "\n",
        "i = 0\n",
        "while i+ 1< temp_2_df.shape[0] :\n",
        "  if temp_2_df['scan_from_station'].iloc[i] == temp_2_df['scan_to_station'].iloc[i+1] and temp_2_df['scan_to_station'].iloc[i] == temp_2_df['scan_from_station'].iloc[i+1]:\n",
        "    df = df.drop(df[(df['barcode'] == temp_2_df['barcode'].iloc[i]) & (df['timestamp'] == temp_2_df['timestamp'].iloc[i])].index)\n",
        "  i = i + 2\n",
        "\n",
        "\n",
        "temp_3 = temp[temp['scan_to_station']==3].reset_index().drop('index',axis=1)\n",
        "temp_3.shape\n",
        "\n",
        "temp_3_df= pd.DataFrame()\n",
        "for i in temp_3.index:\n",
        "  match = df1[(df1['barcode']== temp_3['barcode'].iloc[i]) & (df1['timestamp']==temp_3['timestamp'].iloc[i])]\n",
        "  temp_3_df = pd.concat([temp_3_df,match])\n",
        "\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqEs2wqzQvLR"
      },
      "source": [
        "**Data Cleaning/Validation Part 2**\n",
        "1. Convert Timestamp from string to time\n",
        "2. All values in scan_to_station are present in scan_from_station\n",
        "3. Max Min and Range\n",
        "4. Looking for null values and duplicate values\n",
        "5. Data Sanity Checks for Time Series Data\n",
        "6. Total number of products we are dealing with = Sum of products entered the system daily\n",
        "7. Which products never entered the System during the time frame\n",
        "8. Products which shipped > 1 during the time frame\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmJI40FOQu5-"
      },
      "source": [
        "print(df.shape)\n",
        "print(df.dtypes)\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "print(type(df['timestamp'][1]))\n",
        "\n",
        "print(set(df['scan_to_station']).issubset(set((df['scan_from_station']))))\n",
        "\n",
        "print(min(df['timestamp']))\n",
        "print(max(df['timestamp']))\n",
        "print((max(df['timestamp'])) - (min(df['timestamp'])))\n",
        "\n",
        "print(df.drop_duplicates().shape,df.shape)\n",
        "nulls = df.isnull().sum()\n",
        "print(nulls[nulls > 0])\n",
        "\n",
        "df['date'] = df['timestamp'].map(lambda x: x.date())\n",
        "print(df[df['scan_from_station']=='Customer'].groupby('date').agg({'barcode':'nunique'}))\n",
        "print(df[df['scan_from_station']=='Customer'].groupby('date').agg({'barcode':'nunique'}).sum())\n",
        "\n",
        "df = df.sort_values(by=['barcode','timestamp'])\n",
        "df['timestamp_next'] = df['timestamp'].shift(-1)\n",
        "time = []\n",
        "pd.Series(df['barcode'].unique()).map(generate_time)\n",
        "df['time'] = time\n",
        "\n",
        "print(df[(df['timestamp'].map(lambda x: x.strftime(\"%m\")).astype('int') < 1) | (df['timestamp'].map(lambda x: x.strftime(\"%m\")).astype('int') > 12)])\n",
        "print(df[(df['timestamp'].map(lambda x: x.strftime(\"%d\")).astype('int') < 1) | (df['timestamp'].map(lambda x: x.strftime(\"%d\")).astype('int') > 31)])\n",
        "print(df[(df['timestamp'].map(lambda x: x.strftime(\"%H\")).astype('int') < 0) | (df['timestamp'].map(lambda x: x.strftime(\"%m\")).astype('int') > 24)])\n",
        "print(df[(df['timestamp'].map(lambda x: x.strftime(\"%M\")).astype('int') < 0) | (df['timestamp'].map(lambda x: x.strftime(\"%d\")).astype('int') > 60)])\n",
        "print(df[(df['timestamp'].map(lambda x: x.strftime(\"%S\")).astype('int') < 0) | (df['timestamp'].map(lambda x: x.strftime(\"%d\")).astype('int') > 60)])\n",
        "\n",
        "print(df['barcode'].nunique())\n",
        "\n",
        "print(df[(df['scan_to_station']=='Customer') & (df['scan_from_station']!='Ship')])\n",
        "\n",
        "print(df[df['scan_to_station'] == 'Ship'].groupby('barcode')['timestamp'].count().reset_index().sort_values(by='timestamp',ascending=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRd_KYDyqeQW"
      },
      "source": [
        "**Backlog Products**\n",
        "\n",
        "We are trying to identify products still in the system who joined the system before the week began and therefore demand higher priority \n",
        "1. Create Unique Barcodes set\n",
        "2. Identify if we have backlog products\n",
        "3. Find the barcode of these products (random)\n",
        "4. Flag them for our dashboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz82BPKAqd3D"
      },
      "source": [
        "print(df[df['scan_from_station']=='Customer'].groupby('date').agg({'barcode':'nunique'}))\n",
        "print(df[df['scan_from_station']=='Customer'].groupby('date').agg({'barcode':'nunique'}).sum())\n",
        "print(df['barcode'].unique()) \n",
        "\n",
        "unique_barcodes = pd.DataFrame(df['barcode'].unique())\n",
        "\n",
        "random_products = unique_barcodes[0][~ pd.DataFrame(df['barcode'].unique())[0].isin((df[df['scan_from_station']=='Customer']['barcode']))].reset_index()[0]\n",
        "random_products\n",
        "\n",
        "start = pd.DataFrame()\n",
        "end = pd.DataFrame()\n",
        "for i in range(len(random_products)):\n",
        "  temp_start = pd.DataFrame(df[df['barcode'] == random_products.iloc[i]].sort_values(by='timestamp').reset_index().iloc[0]).T\n",
        "  temp_end = pd.DataFrame(df[df['barcode'] == random_products.iloc[i]].sort_values(by='timestamp',ascending= False).reset_index().iloc[0]).T\n",
        "  start = pd.concat([start,temp_start]) \n",
        "  end = pd.concat([end,temp_end]) \n",
        "\n",
        "start = start.reset_index()\n",
        "end = end.reset_index()\n",
        "start\n",
        "start.drop(['level_0','index'],axis=1,inplace=True)\n",
        "end.drop(['level_0','index'],axis=1,inplace=True)\n",
        "\n",
        "print(pd.merge(df,df.groupby(['barcode']).agg({'timestamp':'min'}), how='inner', left_on = ['barcode','timestamp'],right_on = ['barcode','timestamp']).groupby('barcode')['timestamp'].count().reset_index().sort_values(by='timestamp',ascending = False)['timestamp'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyGAtpd-sin-"
      },
      "source": [
        "**5891 products out of 14402 products entered the system in the past week (backlog)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wmaybosnbjM"
      },
      "source": [
        "**Questions Answered**\n",
        "\n",
        "1. How many times each product entered that station\n",
        "2. How many unique stations do we have"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViruFXuM04-I"
      },
      "source": [
        "barcode_station = pd.crosstab(df['barcode'],df['scan_from_station'])\n",
        "print(barcode_station.head())\n",
        "\n",
        "print(df['scan_to_station'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkAz8_FFrAPu"
      },
      "source": [
        "**Minimum time to finish and actual time**\n",
        "\n",
        "**Products which were Shipped/ Went to Rack/ Retired Saleable/ Missing/ Showroom**\n",
        "\n",
        "1. Find Latest and First Date for Unique Barcodes\n",
        "2. Find Ideal Dates based on when they should have shipped with 100% efficiency\n",
        "3. Add Backlog, Shipped, Rack, Missing, Retired, Missing Columns\n",
        "4. Generate Total Hours, Ideal Hours and Variance \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-EpDZAYkGYq"
      },
      "source": [
        "unique_barcodes['latest_date'] = unique_barcodes[0].map(last_data_point)\n",
        "unique_barcodes['Ideal_last_date_QC'] = unique_barcodes['barcode'].map(ideal_last_data_point_QC)\n",
        "unique_barcodes['first_date'] = unique_barcodes[0].map(first_data_point)\n",
        "unique_barcodes['Ideal_first_date_QC'] = unique_barcodes['barcode'].map(ideal_first_data_point_QC)\n",
        "unique_barcodes['total_days'] = unique_barcodes['latest_date']-  unique_barcodes['first_date']\n",
        "unique_barcodes['Ideal_Days_QC'] = unique_barcodes['Ideal_last_date_QC']-  unique_barcodes['Ideal_first_date_QC']\n",
        "\n",
        "ideal_dates = df.groupby(['barcode','scan_to_station','scan_from_station'])['timestamp'].min().reset_index()\n",
        "\n",
        "ideal_barcode = ideal_dates.groupby(['barcode']).agg({'timestamp':['min','max']}).reset_index()\n",
        "ideal_barcode['ideal_days'] = abs(ideal_barcode.timestamp['max'] - ideal_barcode.timestamp['min'])\n",
        "\n",
        "unique_barcodes = pd.concat([unique_barcodes,ideal_barcode],axis = 1)\n",
        "unique_barcodes.drop(('barcode', ''),axis=1,inplace=True)\n",
        "unique_barcodes.columns = ['barcode','latest_date','Ideal_last_date_QC','first_date','Ideal_first_date_QC','total_days','Ideal_Days_QC','ideal_first_date','ideal_last_date','ideal_days'] \n",
        "\n",
        "random_barcode= pd.DataFrame(data = random_products)\n",
        "random_barcode.columns = ['bar']\n",
        "\n",
        "unique_barcodes = pd.merge(unique_barcodes,random_barcode,how='left',left_on='barcode', right_on='bar')\n",
        "#print(unique_barcodes)\n",
        "\n",
        "#Creating Backlog Column\n",
        "unique_barcodes['Backlog Product'] = np.where(unique_barcodes['bar'].isnull(),0,1)\n",
        "unique_barcodes.drop(['bar'],axis=1,inplace=True)\n",
        "\n",
        "#confirm we got all backlog products\n",
        "unique_barcodes['Backlog Product'].value_counts()\n",
        "\n",
        "#checking if products shipped/rack/retired saleable/missing/showroom\n",
        "unique_barcodes['Rack'] = 0\n",
        "unique_barcodes['Shipped'] = 0\n",
        "unique_barcodes['Ship_Times'] = 0\n",
        "unique_barcodes['Retired Saleable'] = 0\n",
        "unique_barcodes['Missing'] = 0\n",
        "unique_barcodes['Showroom'] = 0\n",
        "unique_barcodes['Spotting'] = 0\n",
        "unique_barcodes['Pressing'] = 0\n",
        "unique_barcodes['Cleaning'] = 0\n",
        "unique_barcodes['Quality Control'] = 0\n",
        "unique_barcodes['Evaluate Product'] = 0\n",
        "\n",
        "\n",
        "for i in range(len(unique_barcodes)):\n",
        "  unique_barcodes['Shipped'][i] = 'Ship' in ' '.join(df[df['barcode'] == unique_barcodes['barcode'].iloc[i]]['scan_to_station']) + ' '.join(df[df['barcode'] == unique_barcodes['barcode'].iloc[i]]['scan_from_station'])\n",
        "  unique_barcodes['Evaluate Product'][i] = 'Evaluate Product' in ' '.join(df[df['barcode'] == unique_barcodes['barcode'].iloc[i]]['scan_to_station']) + ' '.join(df[df['barcode'] == unique_barcodes['barcode'].iloc[i]]['scan_from_station'])\n",
        "  unique_barcodes['Ship_Times'][i] = df[(df['barcode'] == unique_barcodes['barcode'].iloc[i]) & (df['scan_to_station'] == 'Ship')]['scan_to_station'].count()\n",
        "  unique_barcodes['Rack'][i] = 'Rack' in ' '.join(df[df['barcode'] == unique_barcodes['barcode'].iloc[i]]['scan_to_station']) +  ' '.join(df[df['barcode'] == unique_barcodes['barcode'].iloc[1]]['scan_from_station'])\n",
        "  unique_barcodes['Showroom'][i] = 'Showroom Staging' in ' '.join(df[df['barcode'] == unique_barcodes['barcode'].iloc[i]]['scan_to_station']) + ' '.join(df[df['barcode'] == unique_barcodes['barcode'].iloc[i]]['scan_from_station'])\n",
        "  unique_barcodes['Missing'][i] = 'Missing' in ' '.join(df[df['barcode'] == unique_barcodes['barcode'].iloc[i]]['scan_to_station']) +  ' '.join(df[df['barcode'] == unique_barcodes['barcode'].iloc[1]]['scan_from_station'])\n",
        "  unique_barcodes['Retired Saleable'][i] = 'Retired Saleable' in ' '.join(df[df['barcode'] == unique_barcodes['barcode'].iloc[i]]['scan_to_station']) +  ' '.join(df[df['barcode'] == unique_barcodes['barcode'].iloc[1]]['scan_from_station'])\n",
        "  unique_barcodes['Spotting'][i] = df[(df['barcode'] == unique_barcodes['barcode'].iloc[i]) & (df['scan_to_station'] == 'Spotting')]['scan_to_station'].count()\n",
        "  unique_barcodes['Cleaning'][i] = df[(df['barcode'] == unique_barcodes['barcode'].iloc[i]) & (df['scan_to_station'] == 'Cleaning')]['scan_to_station'].count()\n",
        "  unique_barcodes['Pressing'][i] = df[(df['barcode'] == unique_barcodes['barcode'].iloc[i]) & (df['scan_to_station'] == 'Pressing')]['scan_to_station'].count()\n",
        "  unique_barcodes['Quality Control'][i] = df[(df['barcode'] == unique_barcodes['barcode'].iloc[i]) & (df['scan_to_station'] == 'Quality Control')]['scan_to_station'].count()\n",
        "\n",
        "\n",
        "unique_barcodes['total_hours'] = round(unique_barcodes['total_days'].map(lambda x: x.days) * 24 + (unique_barcodes['total_days'].map(lambda x: x.seconds)/60)/60,2)\n",
        "unique_barcodes['ideal_hours'] = round(unique_barcodes['ideal_days'].map(lambda x: x.days) * 24 + (unique_barcodes['ideal_days'].map(lambda x: x.seconds)/60)/60,2)\n",
        "unique_barcodes['Variance'] = round(unique_barcodes['total_hours'] - unique_barcodes['ideal_hours'],2)\n",
        "\n",
        "print(unique_barcodes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbN-bqXEgR55"
      },
      "source": [
        "**Top 10 worse products for all systems daily**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9Gy5CiCg1eN"
      },
      "source": [
        "worse_products = pd.DataFrame()\n",
        "for i in (set(df['scan_to_station'])):\n",
        "  #print(i)\n",
        "  for j in set(df['date']):\n",
        "    temp = pd.DataFrame(df[(df['scan_from_station'] == i) & (df['date'] == j)].sort_values(by='time',ascending= False)['barcode'].head(10).reset_index().drop(['index'],axis = 1,inplace = False))\n",
        "    temp['process'] = i\n",
        "    temp['date'] = j\n",
        "    worse_products = pd.concat([worse_products,temp])\n",
        "\n",
        "print(worse_products)\n",
        "#worse_products.to_csv('Worse_Products.csv')\n",
        "\n",
        "\n",
        "df = pd.merge(df,worse_products,how='left',left_on=['barcode','date','scan_to_station'],right_on=['barcode','date','process'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bpa4L4vir--"
      },
      "source": [
        "**Understanding different segments for Products**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDUlVHrSsxjF"
      },
      "source": [
        "unique_barcodes.groupby(['Shipped','Rack','Backlog Product'])['barcode'].count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EblUQvbXgf_0"
      },
      "source": [
        "**Export Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFdaVMdBnFDZ"
      },
      "source": [
        "unique_barcodes.to_csv('unique_barcodes.csv')\n",
        "df.to_csv('Inbound_Process.csv')\n",
        "worse_products.to_csv('Worse_Products.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCixmd0inShh"
      },
      "source": [
        "**Funcations Used**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8kAoo_1nU5v"
      },
      "source": [
        "def generate_time(bar):\n",
        "  temp = df[df['barcode'] == bar].sort_values(by='timestamp')['timestamp'].diff()\n",
        "  return time.extend(temp.map(lambda x: round((x.total_seconds() / 60),2)))\n",
        "\n",
        "\n",
        "def last_data_point(bar):\n",
        "    #print(bar)\n",
        "    temp = df[df['barcode'] == bar].sort_values(by='timestamp',ascending = False)['timestamp']\n",
        "    return temp.iloc[0]\n",
        "\n",
        "def ideal_first_data_point_QC(bar):\n",
        "    #print(bar)\n",
        "    temp = df[df['barcode'] == bar].sort_values(by='timestamp')\n",
        "    try:\n",
        "      return temp[temp['scan_to_station']=='Quality Control']['timestamp'].iloc[0]\n",
        "    except:\n",
        "      return temp['timestamp'].iloc[0]\n",
        "\n",
        "def ideal_last_data_point_QC(bar):\n",
        "    #print(bar)\n",
        "    temp = df[df['barcode'] == bar].sort_values(by='timestamp',ascending=False)\n",
        "    try:\n",
        "      return temp[temp['scan_to_station']=='Quality Control']['timestamp'].iloc[0]\n",
        "    except:\n",
        "      return temp['timestamp'].iloc[0]\n",
        "\n",
        "\n",
        "def first_data_point(bar):\n",
        "    #print(bar)\n",
        "    temp = df[df['barcode'] == bar].sort_values(by='timestamp')['timestamp']\n",
        "    return temp.iloc[0]\n",
        "\n",
        "def set_values(df,df2):\n",
        "  for i in df2:\n",
        "    i.isin(df)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}